{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials = pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Init/fit\n",
    "ovr = OneVsRestClassifier(estimator=Perceptron())\n",
    "\n",
    "# Build feature/target arrays\n",
    "X, y = financials.drop(\"Fraud\", axis=1), financials[\"Fraud\"].values.flatten()\n",
    "\n",
    "# encode species label numerically \n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Create train/test sets, where test set is 25% of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1121218, test_size=_ _ _, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting our data into our dependent and independent variables.\n",
    "# Create a variable called 'X' and assign it the density field of wine.\n",
    "# Create a variable called 'y' (that's right, lower case) and assign it the fixed.acidity field of wine. \n",
    "# Using double brackets allows us to use the column headings. \n",
    "X = financials[['OldDest']]\n",
    "y = financials[['NewDest']]\n",
    "\n",
    "# Split the data. This line uses the sklearn function train_test_split().\n",
    "# The test_size parameter means we can train with 75% of the data, and test on 25%. \n",
    "# The random_state parameter allows our work to be checked and replicated by other data scientists\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe that contain only 3 columns: \"1_sepal_length\", \"2_sepal_width\",'variety'\n",
    "df1 = financials[[\"Amount\", \"NewDest\",\"Fraud\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup X and y data\n",
    "\n",
    "# select first 2 columns for X\n",
    "X_data = df1.iloc[:,0:2]\n",
    "\n",
    "# select \"variety\" column for \"y\", and replace all Setosa, Versicolor, and Virginica encodings with 0,1, and 2 respectively\n",
    "y_labels = df1.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit your model\n",
    "\n",
    "model_sk = GaussianNB()\n",
    "\n",
    "#Fit a Gaussian Naive Bayes model using X_date and y_labels\n",
    "model_sk.fit(X_data, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for decision boundary plot\n",
    "N = 100\n",
    "X = np.linspace(4, 8, N)\n",
    "Y = np.linspace(1.5, 5, N)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "color_list = ['Blues','Greens','Reds']\n",
    "my_norm = colors.Normalize(vmin=-1.,vmax=1.)\n",
    "\n",
    "g = sns.FacetGrid(financials, hue=\"Fraud\", height=10, aspect=1.5, palette = 'colorblind') .map(plt.scatter, \"Amount\", \"OldDest\",).add_legend()\n",
    "my_ax = g.ax\n",
    "\n",
    "\n",
    "#Computing the predicted class function for each value on the grid\n",
    "zz = np.array(  [model_sk.predict( [[xx,yy]])[0] for xx, yy in zip(np.ravel(X), np.ravel(Y)) ] )\n",
    "\n",
    "\n",
    "#Reshaping the predicted class into the meshgrid shape\n",
    "Z = zz.reshape(X.shape)\n",
    "\n",
    "\n",
    "#Plot the filled and boundary contours\n",
    "my_ax.contourf( X, Y, Z, 2, alpha = .1, colors = ('blue','green','red'))\n",
    "my_ax.contour( X, Y, Z, 2, alpha = 1, colors = ('blue','green','red'))\n",
    "\n",
    "# Addd axis and title\n",
    "my_ax.set_xlabel('Sepal length')\n",
    "my_ax.set_ylabel('Sepal width')\n",
    "my_ax.set_title('Gaussian Naive Bayes decision boundaries')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions on our `X_data`\n",
    "y_hat = model_sk.predict(X_data)\n",
    "\n",
    "labels = y_labels.unique()\n",
    "\n",
    "# create the corresponding confusion matrix \n",
    "matrix = confusion_matrix(y_labels, y_hat, labels=labels, normalize=None)\n",
    "# let's contextualize this confusion matrix via the \"classification_report\" method which provides different metrics used to view performance of our classifiers\n",
    "print(Not Fraud = 0, Fraud = 1, and Virginica = 2\")\n",
    "\n",
    "print(classification_report(y_labels, y_hat, labels=labels))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
